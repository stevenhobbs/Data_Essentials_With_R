---
title: "7. MISSING VALUES"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
  html_notebook: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
pacman::p_load(knitr, tidyverse, kableExtra)
opts_chunk$set(echo = TRUE, message=FALSE, warnings = FALSE)
```

## NA, <Na>, NaN & non-standard missing values.

### Recoding non-standard missing values as NA

R represents missing numeric with "NA" for numeric variables and "<NA>" for character variables. R also uses NaN for numeric values that are undefined, such as zero divided by zero. Unfortunately, the coding scheme for missing values is not universal. Other conventions include using white space, a dash, the value 99, the value 999, N/A, n/a, and many others. For R to understand these as missing values, we merely have to include an argument to read_csv that lists all the ways missing values are coded in the raw data. 

Let's imagine that different parts of a cholesterol data set were produced by different technologies and different people.  Perhaps the name, age and gender of study participants were collected from a paper-based bubble-in form and occasionally people skip questions. Perhaps the initial weight was recorded manually by a technician that used one convention for missing values, while the final weight was recorded by a different technician who used another. Lastly, perhaps the cholesterol values were generated by a medical device that uses a fourth convention for missing values. Now let's imagine that none of them use "NA" to code for missing values. What a nightmare!

One option is to open the file in Excel and manually fix all the missing values to read NA. This is a tedious and error prone process though, and possibly impractical for extremely large data sets. Secondly, this practice changes the raw data! Even with the best intentions, directly altering the raw data file is dangerous and ill-advised for reasons already discussed.

Fortunately, a single argument to the read_csv command may be able to solve all of these problems. First though, let's import a dataframe with the problems mentioned above and use the summary command to explore the data.

```{r}
read_csv('data/Friends_Cholesterol_Missing.csv') %>% summary
```

From the output, we can see clear evidence of problems. The maximum value of gender is 999, and the weight and cholesterol variables are all interpreted as character variables. To explore the problem further, we can view the first 10 rows of our data using the head command.

```{r}
read_csv('data/Friends_Cholesterol_Missing.csv') %>% head(10)
```

The output above is quite revealing. We can see that missing values are coded as 999, N/A, ### and "missing". Now we merely need to run the import command again with an "na =" argument that identifies all the missing value codes with a string vector.

```{r}
read_csv('data/Friends_Cholesterol_Missing.csv', na = c(999, "N/A", "###", "missing")) %>% summary
```

Viola! All missing values are now coded as "NA", R's internal structure for missing values.

## Dealing with NA's

Missing values can cause commands to fail, produce anomalies in plots and cause other problems. If missing values can be replaced with real values, without invalidating the study, this is obviously the best solution. When we are really stuck with missing values though, we have four common strategies in R.

1. Ignore missing values from inside commands using the na.rm = TRUE argument.
2. Remove rows with missing values for a single variable using filter(df, is.na(<variable name>)).
3. Remove rows with any missing value using filter(df, complete.cases(df)). 
4. Impute the missing values (replace NA with a "best guess").

Before exploring these approaches, let's clear our environment, import new data and identify the presence or absence of missing values using the summary command.

```{r}
rm(list = ls())
df <-
    read_csv("data/cardiac.csv") %>%
    mutate(sex = factor(sex),
           sex = fct_recode(sex, 'female' = '0', 'male' = '1'))
    
summary(df)
```

By inspecting the output, we can see that three variables, weight_t2, systolic_t2, and diastolic_t2 17 each have 17 missing values. Three other variables, weight_t4, systolic_t4 and diastolic_t4 variables, have missing 30 missing values each. Let's see what happens when we try to generate descriptive statistics with variables that have missing values.

```{r}
mean(df$systolic_t2)
tapply(df$weight_t2, df$sex, max)
```

Assuming we are executing code sequentially within the script (I.E. top to bottom), we should see "NA" returned for both of the above commands. The commands didn't fail to execute or throw an error, they merely returned (mostly) useless information. Essentially, R is telling us that missing values exist and we must either fix the problem or explicitly tell R to ignore missing values. 

### na.rm = TRUE

We can usually tell R to ignore missing values by including the optional argument, na.rm = TRUE. An advantage to this approach is that we do not change the dataframe, such as by eliminating an entire row with 1 or more missing values. Let's run the same commands as above, but with the na.rm = TRUE argument.

```{r}
mean(df$systolic_t2, na.rm = TRUE)
tapply(df$weight_t2, df$sex, max, na.rm = TRUE)
```

Problem solved!

### na.omit & complete.cases

We sometimes wish to evaluate just the cases that have no missing values, the complete cases, as well as characterize the cases that have one or more missing values. Perhaps we wish to know if the missing values are randomly spread through the data, or if they are concentrated in a particular group. We can accomplish this by splitting our dataframe into two versions, one with complete cases and one with incomplete cases. 

The na.omit(df) command needs only one argument, a dataframe, and it outputs a dataframe with no missing values. The complete.cases command takes the same input, a dataframe, but outputs a logical vector. Rows that have no missing values will return TRUE, while those with 1 or more NA values will return FALSE. The complete.cases command is most often used in combination with commands such as filter that take logical arguments, or with commands that perform some arithmetic function based on the quantitative attribute of all logical variables, TRUE = 0 and FALSE = 1.

#### summarizing the complete cases

Below we first count the complete and incomplete cases in df. Then we create two new dataframes with observations that have no missing values using na.omit and complete.cases. Next we count the complete rows using nrow and create summary statistics with the summary command. Lastly, we verify that the dataframes created with na.omit and complete.cases contain the same information.

```{r}
# Count the complete and incomplete cases
complete.cases(df) %>% summary

# Equivalent approaches for creating dataframes with complete cases
df.c <- filter(df, complete.cases(df)) 
df.o <- na.omit(df)

# Explore the complete cases
nrow(df.c)
summary(df.c)

# verify that both approaches produce the same information
all.equal(summary(df.c), summary(df.o))
```

Warning, the dataframes with exclusively complete cases should be used with caution! If a certain row has a missing value for just one variable, the commands above will remove the entire row, discarding useful information in the columns with observed values. Using these dataframes for subsequent analyses can then produce erroneous results that don't involve all the original data. Consequently, the dataframes above are often utilized just to exploring the data and look for patterns related to missing values. 

#### summarizing the incomplete cases

To produce a dataframe of incomplete observations, we need only add the negation operator, !, in front of complete.cases. Negation will switch all the TRUE and FALSE values. Our filter command will now retain observations WITH one or more missing values. Below we create a new dataframe with only the observations that have missing values. Then we count the rows with nrow and create summary statistics with the summary command.

```{r}
df.m <- filter(df, !complete.cases(df)) 
nrow(df.m)
summary(df.m)
```

### is.na

As an alternative to filtering rows with any missing values, we can filter based on a single variable using is.na. Like complete.cases, is.na is a logical operator that returns TRUE or FALSE. Unlike complete.cases, is.na takes a single variable as an argument. We should still be careful when using is.na though, as filtering a dataframe with an is.na argument can still throw away useful information. For example, the filtering command below, throws away ALL information in rows that have a missing weight_t2 value.

```{r}
df.c.weight_t2 <- df %>% filter(!is.na(weight_t2))

nrow(df)
nrow(df.c)
nrow(df.c.weight_t2)
```

One good use of is.na is for including missing value counts in summary tables created with summarize as shown below. Logical output can be quantified numerically because the output actually has numeric value, TRUE = 0 and FALSE = 1. The approach below using summarize below provides useful information without changing our dataframe or cluttering our environment with additional objects.

```{r}
summarize(df,
          'total observations' = n(), # n() is a tidyverse command for counting rows
          'complete observations' = sum(complete.cases(df)),
          'time 2 average weight' = mean(weight_t2, na.rm = TRUE),
          'time 2 missing values' = sum(is.na(weight_t2))) %>%
    round %>%
    kable %>% kable_classic(full_width = F)
```


### Imputation

Advanced statistical approaches sometimes benefit from replacing missing values with a best guess. If our best guesses are better than random guess, we often achieve a predictive model that is more accurate than one that ignores missing values. While these statistical models are well beyond the scope of this course, the process of imputation can be straight forward. For example, in the chunk below we use the replace command inside of mutate to replace all NAs for the weight_t2 variable with the median value of weight_2. 

```{r}
df %>% 
    mutate(weight_t2 = replace(weight_t2,
                               is.na(weight_t2),
                               median(weight_t2, na.rm = TRUE))) %>%
    summary()
```

Note that we could have also used the arithmetic average (the mean) of weight_t2 to impute values. Even better would be to use values that are based on correlations within the data. For example, if two subjects, A and B, are the same sex, age, height and weight and have similar initial and final hdl cholesterol and similar initial ldl cholesterol levels, it is reasonable to guess that they their final ldl cholesterol levels will be similar. If this value is missing for subject B, one strategy is to use subject A's ldl cholesterol as a best guess for subject B. Methods exist that take advantage of these correlations to impute missing values, but they are well outside the scope of this course.
